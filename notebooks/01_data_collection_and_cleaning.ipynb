{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyUSGWR1HZ_s"
   },
   "source": [
    "# Rush Hour Reality - Data Collection\n",
    "## Dublin Bus Delays Analysis\n",
    "\n",
    "This notebook collects real-time GTFS data from Dublin Bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22636,
     "status": "ok",
     "timestamp": 1764549853794,
     "user": {
      "displayName": "Arun Narayanan",
      "userId": "15971492864752892976"
     },
     "user_tz": 0
    },
    "id": "AKU1ZAheHuvs",
    "outputId": "a217a5f6-c370-42b5-fb20-4eca20b44f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gtfs-realtime-bindings==1.0.0 in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from gtfs-realtime-bindings==1.0.0) (75.2.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from gtfs-realtime-bindings==1.0.0) (5.29.5)\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (1.31.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (5.29.5)\n",
      "All packages installed successfully\n"
     ]
    }
   ],
   "source": [
    "# RUSH HOUR REALITY - Data Collection Script\n",
    "# Dublin Bus Real-Time Delay Analysis\n",
    "# Team: ZA\n",
    "# Date: November 7, 2025\n",
    "\n",
    "# Install Required Packages\n",
    "!pip install gtfs-realtime-bindings==1.0.0\n",
    "!pip install polars\n",
    "!pip install requests\n",
    "!pip install protobuf\n",
    "\n",
    "print(\"All packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1764549865212,
     "user": {
      "displayName": "Arun Narayanan",
      "userId": "15971492864752892976"
     },
     "user_tz": 0
    },
    "id": "8R8W0wymIGbI",
    "outputId": "ee013228-56b3-480d-9041-80e122f38e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import requests\n",
    "import polars as pl\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "print(\"All libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1764549878773,
     "user": {
      "displayName": "Arun Narayanan",
      "userId": "15971492864752892976"
     },
     "user_tz": 0
    },
    "id": "hDsD0J06Ilqd",
    "outputId": "d238067b-44f5-4f08-eeb3-88cab4c023a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded from Colab Secrets\n",
      "Configuration set\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "# Got the API key from: https://developer.nationaltransport.ie/\n",
    "\n",
    "# Stored API key securely\n",
    "from google.colab import userdata\n",
    "\n",
    "try:\n",
    "    NTA_API_KEY = userdata.get('NTA_API_KEY')\n",
    "    print(\"API Key loaded from Colab Secrets\")\n",
    "except:\n",
    "    print(\"API Load Fail\")\n",
    "\n",
    "# API Endpoints\n",
    "GTFS_REALTIME_URL = \"https://api.nationaltransport.ie/gtfsr/v2/TripUpdates\"\n",
    "VEHICLE_POSITIONS_URL = \"https://api.nationaltransport.ie/gtfsr/v2/Vehicles\"\n",
    "\n",
    "# Static GTFS Data URL (for reference data)\n",
    "STATIC_GTFS_URL = \"https://www.transportforireland.ie/transitData/Data/GTFS_All.zip\"\n",
    "\n",
    "print(\"Configuration set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1764549905514,
     "user": {
      "displayName": "Arun Narayanan",
      "userId": "15971492864752892976"
     },
     "user_tz": 0
    },
    "id": "rZhDI0OkJwvZ",
    "outputId": "091dbcd7-03be-4624-9b4d-9a70a747666e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined successfully\n"
     ]
    }
   ],
   "source": [
    "# Helper Functions for GTFS-R Data Parsing\n",
    "\n",
    "def fetch_gtfs_realtime_data(url: str, api_key: str) -> gtfs_realtime_pb2.FeedMessage:\n",
    "    \"\"\"\n",
    "    Fetch GTFS-Realtime data from NTA API\n",
    "\n",
    "    Args:\n",
    "        url: API endpoint URL\n",
    "        api_key: Your NTA API subscription key\n",
    "\n",
    "    Returns:\n",
    "        FeedMessage: Parsed protobuf message\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'x-api-key': api_key,\n",
    "        'Cache-Control': 'no-cache'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Parse protobuf\n",
    "        feed = gtfs_realtime_pb2.FeedMessage()\n",
    "        feed.ParseFromString(response.content)\n",
    "\n",
    "        return feed\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_trip_updates_to_dict(feed: gtfs_realtime_pb2.FeedMessage) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Parse trip updates from protobuf to list of dictionaries\n",
    "\n",
    "    Args:\n",
    "        feed: GTFS-Realtime FeedMessage\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries with trip update data\n",
    "    \"\"\"\n",
    "    trip_updates = []\n",
    "    timestamp = datetime.fromtimestamp(feed.header.timestamp, tz=timezone.utc)\n",
    "\n",
    "    for entity in feed.entity:\n",
    "        if entity.HasField('trip_update'):\n",
    "            trip = entity.trip_update.trip\n",
    "            vehicle = entity.trip_update.vehicle\n",
    "\n",
    "            # Extract stop time updates\n",
    "            for stop_time_update in entity.trip_update.stop_time_update:\n",
    "                record = {\n",
    "                    'collection_timestamp': timestamp.isoformat(),\n",
    "                    'entity_id': entity.id,\n",
    "                    'trip_id': trip.trip_id if trip.HasField('trip_id') else None,\n",
    "                    'route_id': trip.route_id if trip.HasField('route_id') else None,\n",
    "                    'direction_id': trip.direction_id if trip.HasField('direction_id') else None,\n",
    "                    'start_date': trip.start_date if trip.HasField('start_date') else None,\n",
    "                    'start_time': trip.start_time if trip.HasField('start_time') else None,\n",
    "                    'vehicle_id': vehicle.id if vehicle.HasField('id') else None,\n",
    "                    'vehicle_label': vehicle.label if vehicle.HasField('label') else None,\n",
    "                    'stop_sequence': stop_time_update.stop_sequence if stop_time_update.HasField('stop_sequence') else None,\n",
    "                    'stop_id': stop_time_update.stop_id if stop_time_update.HasField('stop_id') else None,\n",
    "                    'arrival_delay': stop_time_update.arrival.delay if stop_time_update.HasField('arrival') and stop_time_update.arrival.HasField('delay') else None,\n",
    "                    'arrival_time': stop_time_update.arrival.time if stop_time_update.HasField('arrival') and stop_time_update.arrival.HasField('time') else None,\n",
    "                    'departure_delay': stop_time_update.departure.delay if stop_time_update.HasField('departure') and stop_time_update.departure.HasField('delay') else None,\n",
    "                    'departure_time': stop_time_update.departure.time if stop_time_update.HasField('departure') and stop_time_update.departure.HasField('time') else None,\n",
    "                }\n",
    "\n",
    "                trip_updates.append(record)\n",
    "\n",
    "    return trip_updates\n",
    "\n",
    "\n",
    "def parse_vehicle_positions_to_dict(feed: gtfs_realtime_pb2.FeedMessage) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Parse vehicle positions from protobuf to list of dictionaries\n",
    "\n",
    "    Args:\n",
    "        feed: GTFS-Realtime FeedMessage\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries with vehicle position data\n",
    "    \"\"\"\n",
    "    vehicle_positions = []\n",
    "    timestamp = datetime.fromtimestamp(feed.header.timestamp, tz=timezone.utc)\n",
    "\n",
    "    for entity in feed.entity:\n",
    "        if entity.HasField('vehicle'):\n",
    "            vehicle = entity.vehicle\n",
    "            trip = vehicle.trip\n",
    "            position = vehicle.position\n",
    "\n",
    "            record = {\n",
    "                'collection_timestamp': timestamp.isoformat(),\n",
    "                'entity_id': entity.id,\n",
    "                'vehicle_id': vehicle.vehicle.id if vehicle.HasField('vehicle') and vehicle.vehicle.HasField('id') else None,\n",
    "                'vehicle_label': vehicle.vehicle.label if vehicle.HasField('vehicle') and vehicle.vehicle.HasField('label') else None,\n",
    "                'trip_id': trip.trip_id if trip.HasField('trip_id') else None,\n",
    "                'route_id': trip.route_id if trip.HasField('route_id') else None,\n",
    "                'direction_id': trip.direction_id if trip.HasField('direction_id') else None,\n",
    "                'start_date': trip.start_date if trip.HasField('start_date') else None,\n",
    "                'start_time': trip.start_time if trip.HasField('start_time') else None,\n",
    "                'latitude': position.latitude if position.HasField('latitude') else None,\n",
    "                'longitude': position.longitude if position.HasField('longitude') else None,\n",
    "                'bearing': position.bearing if position.HasField('bearing') else None,\n",
    "                'speed': position.speed if position.HasField('speed') else None,\n",
    "                'current_stop_sequence': vehicle.current_stop_sequence if vehicle.HasField('current_stop_sequence') else None,\n",
    "                'stop_id': vehicle.stop_id if vehicle.HasField('stop_id') else None,\n",
    "                'current_status': vehicle.current_status if vehicle.HasField('current_status') else None,\n",
    "                'timestamp': vehicle.timestamp if vehicle.HasField('timestamp') else None,\n",
    "                'congestion_level': vehicle.congestion_level if vehicle.HasField('congestion_level') else None,\n",
    "            }\n",
    "\n",
    "            vehicle_positions.append(record)\n",
    "\n",
    "    return vehicle_positions\n",
    "\n",
    "print(\"Helper functions defined successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1080,
     "status": "ok",
     "timestamp": 1764549935575,
     "user": {
      "displayName": "Arun Narayanan",
      "userId": "15971492864752892976"
     },
     "user_tz": 0
    },
    "id": "_7fIQrr2KB9B",
    "outputId": "5e8fbcbd-1e20-4524-eca8-6c2e71252d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing NTA API connection \n",
      "\n",
      "Testing Trip Updates endpoint\n",
      "Trip Updates: Received 235 entities\n",
      "Feed timestamp: 2025-12-01 00:45:35+00:00\n",
      "\n",
      "Testing Vehicle Positions endpoint\n",
      "Vehicle Positions: Received 128 entities\n",
      "Feed timestamp: 2025-12-01 00:45:30+00:00\n",
      "\n",
      "API connection test complete\n"
     ]
    }
   ],
   "source": [
    "# Test API Connection\n",
    "\n",
    "print(\"Testing NTA API connection \\n\")\n",
    "\n",
    "# Test Trip Updates endpoint\n",
    "print(\"Testing Trip Updates endpoint\")\n",
    "trip_feed = fetch_gtfs_realtime_data(GTFS_REALTIME_URL, NTA_API_KEY)\n",
    "\n",
    "if trip_feed:\n",
    "    print(f\"Trip Updates: Received {len(trip_feed.entity)} entities\")\n",
    "    print(f\"Feed timestamp: {datetime.fromtimestamp(trip_feed.header.timestamp, tz=timezone.utc)}\")\n",
    "else:\n",
    "    print(\"Failed to fetch Trip Updates\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test Vehicle Positions endpoint\n",
    "print(\"Testing Vehicle Positions endpoint\")\n",
    "vehicle_feed = fetch_gtfs_realtime_data(VEHICLE_POSITIONS_URL, NTA_API_KEY)\n",
    "\n",
    "if vehicle_feed:\n",
    "    print(f\"Vehicle Positions: Received {len(vehicle_feed.entity)} entities\")\n",
    "    print(f\"Feed timestamp: {datetime.fromtimestamp(vehicle_feed.header.timestamp, tz=timezone.utc)}\")\n",
    "else:\n",
    "    print(\"Failed to fetch Vehicle Positions\")\n",
    "\n",
    "print(\"\\nAPI connection test complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1764550699917,
     "user": {
      "displayName": "Arun Narayanan",
      "userId": "15971492864752892976"
     },
     "user_tz": 0
    },
    "id": "1WoKTgUgLUlp",
    "outputId": "2cccb028-facc-49ed-e1c4-7f5f65bdebfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect_and_save_data function loaded\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "# Collect and save data with explicit schema\n",
    "\n",
    "def collect_and_save_data(api_key: str, output_dir: str = './data/raw'):\n",
    "    \"\"\"\n",
    "    Collect data from NTA API and save to CSV with timestamp\n",
    "    Uses explicit schema to avoid type inference errors\n",
    "\n",
    "    Args:\n",
    "        api_key: NTA API key\n",
    "        output_dir: Directory to save CSV files\n",
    "\n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    success = True\n",
    "\n",
    "    # Collect Trip Updates\n",
    "    print(f\"[{timestamp_str}] Fetching trip updates\")\n",
    "    trip_feed = fetch_gtfs_realtime_data(GTFS_REALTIME_URL, api_key)\n",
    "\n",
    "    if trip_feed:\n",
    "        try:\n",
    "            trip_data = parse_trip_updates_to_dict(trip_feed)\n",
    "\n",
    "            if trip_data:\n",
    "                # Create DataFrame with schema\n",
    "                df_trips = pl.DataFrame(\n",
    "                    trip_data,\n",
    "                    schema={\n",
    "                        'collection_timestamp': pl.Utf8,\n",
    "                        'entity_id': pl.Utf8,\n",
    "                        'trip_id': pl.Utf8,\n",
    "                        'route_id': pl.Utf8,\n",
    "                        'direction_id': pl.Int64,\n",
    "                        'start_date': pl.Utf8,\n",
    "                        'start_time': pl.Utf8,\n",
    "                        'vehicle_id': pl.Utf8,\n",
    "                        'vehicle_label': pl.Utf8,\n",
    "                        'stop_sequence': pl.Int64,\n",
    "                        'stop_id': pl.Utf8,\n",
    "                        'arrival_delay': pl.Int64,\n",
    "                        'arrival_time': pl.Int64,\n",
    "                        'departure_delay': pl.Int64,\n",
    "                        'departure_time': pl.Int64,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                trip_file = f\"{output_dir}/trip_updates_{timestamp_str}.csv\"\n",
    "                df_trips.write_csv(trip_file)\n",
    "                print(f\"Saved {len(df_trips):,} trip records to {trip_file}\")\n",
    "            else:\n",
    "                print(\"No trip update data received\")\n",
    "                success = False\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing trip updates: {e}\")\n",
    "            success = False\n",
    "    else:\n",
    "        print(\"Failed to fetch trip updates\")\n",
    "        success = False\n",
    "\n",
    "    # Collect Vehicle Positions\n",
    "    print(f\"[{timestamp_str}] Fetching vehicle positions\")\n",
    "    vehicle_feed = fetch_gtfs_realtime_data(VEHICLE_POSITIONS_URL, api_key)\n",
    "\n",
    "    if vehicle_feed:\n",
    "        try:\n",
    "            vehicle_data = parse_vehicle_positions_to_dict(vehicle_feed)\n",
    "\n",
    "            if vehicle_data:\n",
    "                # Create DataFrame with schema\n",
    "                df_vehicles = pl.DataFrame(\n",
    "                    vehicle_data,\n",
    "                    schema={\n",
    "                        'collection_timestamp': pl.Utf8,\n",
    "                        'entity_id': pl.Utf8,\n",
    "                        'vehicle_id': pl.Utf8,\n",
    "                        'vehicle_label': pl.Utf8,\n",
    "                        'trip_id': pl.Utf8,\n",
    "                        'route_id': pl.Utf8,\n",
    "                        'direction_id': pl.Int64,\n",
    "                        'start_date': pl.Utf8,\n",
    "                        'start_time': pl.Utf8,\n",
    "                        'latitude': pl.Float64,\n",
    "                        'longitude': pl.Float64,\n",
    "                        'bearing': pl.Float64,\n",
    "                        'speed': pl.Float64,\n",
    "                        'current_stop_sequence': pl.Int64,\n",
    "                        'stop_id': pl.Utf8,\n",
    "                        'current_status': pl.Int64,\n",
    "                        'timestamp': pl.Int64,\n",
    "                        'congestion_level': pl.Int64,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                vehicle_file = f\"{output_dir}/vehicle_positions_{timestamp_str}.csv\"\n",
    "                df_vehicles.write_csv(vehicle_file)\n",
    "                print(f\"Saved {len(df_vehicles):,} vehicle records to {vehicle_file}\")\n",
    "            else:\n",
    "                print(\"No vehicle position data received\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing vehicle positions: {e}\")\n",
    "            # Ignore failure if trip updates succeeded\n",
    "    else:\n",
    "        print(\"Failed to fetch vehicle positions\")\n",
    "\n",
    "    print()\n",
    "    return success\n",
    "\n",
    "\n",
    "print(\"Collect_and_save_data function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3n1gejwJmlwV"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "%cd /content/drive/MyDrive/Rush-Hour-Reality/rush-hour-reality/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158418,
     "status": "ok",
     "timestamp": 1764550988385,
     "user": {
      "displayName": "Arun Narayanan",
      "userId": "15971492864752892976"
     },
     "user_tz": 0
    },
    "id": "vteFxywtL6GZ",
    "outputId": "f912c55c-92a3-4584-b499-4e6980dfaa34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading static GTFS data\n",
      "Static GTFS data downloaded and extracted\n",
      "Routes: 806 records\n",
      "Stops: 14055 records\n",
      "Trips: 356741 records\n"
     ]
    }
   ],
   "source": [
    "# Download static GTFS reference data\n",
    "\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import polars as pl\n",
    "\n",
    "print(\"Downloading static GTFS data\")\n",
    "\n",
    "# Download the zip file\n",
    "urllib.request.urlretrieve(STATIC_GTFS_URL, 'gtfs_static.zip')\n",
    "\n",
    "# Extract\n",
    "with zipfile.ZipFile('gtfs_static.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/gtfs_static/')\n",
    "\n",
    "print(\"Static GTFS data downloaded and extracted\")\n",
    "\n",
    "# Load key reference files with Polars\n",
    "df_routes = pl.read_csv('./data/gtfs_static/routes.txt')\n",
    "df_stops = pl.read_csv('./data/gtfs_static/stops.txt')\n",
    "df_trips = pl.read_csv('./data/gtfs_static/trips.txt')\n",
    "\n",
    "print(f\"Routes: {len(df_routes)} records\")\n",
    "print(f\"Stops: {len(df_stops)} records\")\n",
    "print(f\"Trips: {len(df_trips)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVjbWOsSeSuC"
   },
   "outputs": [],
   "source": [
    "# Collection loop\n",
    "\n",
    "def run_continuous_collection(interval_minutes: int = 30):\n",
    "    \"\"\"Run continuous collection every N minutes\"\"\"\n",
    "    collection_count = 0\n",
    "\n",
    "    while True:\n",
    "        collection_count += 1\n",
    "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        print(f\"Collection #{collection_count} started at {current_time}\")\n",
    "\n",
    "\n",
    "        success = collect_and_save_data(NTA_API_KEY)\n",
    "        if success:\n",
    "            print(f\"Collection #{collection_count} completed successfully\")\n",
    "        else:\n",
    "            print(f\"Collection #{collection_count} completed with warnings\")\n",
    "\n",
    "\n",
    "        # Calculate next collection time\n",
    "        next_time = datetime.now()\n",
    "        next_hour = (next_time.hour + (next_time.minute + interval_minutes) // 60) % 24\n",
    "        next_minute = (next_time.minute + interval_minutes) % 60\n",
    "        next_time = next_time.replace(hour=next_hour, minute=next_minute, second=0, microsecond=0)\n",
    "\n",
    "        print(f\"Next collection scheduled at {next_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Sleeping for {interval_minutes} minutes\")\n",
    "\n",
    "        time.sleep(interval_minutes * 60)\n",
    "\n",
    "# Entry point\n",
    "print(\"Starting rush hour collection script\")\n",
    "print(\"Starting collection in 3 seconds\")\n",
    "time.sleep(3)\n",
    "run_continuous_collection(interval_minutes=30)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
